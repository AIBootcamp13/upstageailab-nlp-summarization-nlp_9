# prepare_data.py
import pandas as pd
from sklearn.model_selection import train_test_split
import os

print("ğŸš€ ë°ì´í„° ì¤€ë¹„ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...")

# 1. ì›ë³¸ ë°ì´í„° íŒŒì¼ ê²½ë¡œ
source_file = 'data/processed/translation_checkpoint.csv'

# 2. ê²°ê³¼ ì €ì¥ ê²½ë¡œ
output_dir = 'data/processed'
train_file = os.path.join(output_dir, 'train.csv')
val_file = os.path.join(output_dir, 'val.csv')

# 3. ë°ì´í„° ë¡œë“œ
try:
    df = pd.read_csv(source_file)
    print(f"âœ… ì›ë³¸ ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(df)}ê°œ í–‰")
except FileNotFoundError:
    print(f"ğŸ”¥ğŸ”¥ğŸ”¥ ì—ëŸ¬: '{source_file}' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê²½ë¡œë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
    exit()

# ğŸ”¥ğŸ”¥ğŸ”¥ í•µì‹¬ ìˆ˜ì •: ë¹ˆ ìš”ì•½ë¬¸ì´ ìˆëŠ” í–‰ì„ ì „ë¶€ ì œê±°! ğŸ”¥ğŸ”¥ğŸ”¥
original_rows = len(df)
df.dropna(subset=['english_dialogue', 'english_summary', 'english_topic'], inplace=True)
if len(df) < original_rows:
    print(f"âœ… ë¹„ì–´ìˆëŠ” í–‰ {original_rows - len(df)}ê°œë¥¼ ì œê±°í–ˆìŠµë‹ˆë‹¤.")


# 4. í•„ìš”í•œ ì˜ì–´ ì»¬ëŸ¼ë§Œ ì„ íƒ
columns_to_use = ['english_dialogue', 'english_summary', 'english_topic']
df_english = df[columns_to_use].copy()

# 5. Flan-T5 ëª¨ë¸ì— ìµœì í™”ëœ ì…ë ¥ í˜•ì‹(input_text) ìƒì„±
def create_input_text(row):
    return f"summarize: topic: {row['english_topic']} dialogue: {row['english_dialogue']}"

df_english['input_text'] = df_english.apply(create_input_text, axis=1)

# 6. ìµœì¢…ì ìœ¼ë¡œ ì‚¬ìš©í•  ì»¬ëŸ¼ë§Œ ë‚¨ê¸°ê¸°
df_final = df_english[['input_text', 'english_summary']]
print("âœ… 'input_text' ì»¬ëŸ¼ ìƒì„± ì™„ë£Œ.")

# 7. í›ˆë ¨ ë°ì´í„°ì™€ ê²€ì¦ ë°ì´í„°ë¡œ ë¶„í•  (95% í›ˆë ¨, 5% ê²€ì¦)
train_df, val_df = train_test_split(df_final, test_size=0.05, random_state=42)
print(f"âœ… ë°ì´í„°ë¥¼ í›ˆë ¨ ì„¸íŠ¸({len(train_df)}ê°œ)ì™€ ê²€ì¦ ì„¸íŠ¸({len(val_df)}ê°œ)ë¡œ ë¶„í•  ì™„ë£Œ.")


# --- ê°œì„ ì : ì…ë ¥ ê·œì œë¥¼ ìœ„í•œ 'Topic Dropout' ---
# í›ˆë ¨ ë°ì´í„°ì˜ 10%ì— í•´ë‹¹í•˜ëŠ” ìƒ˜í”Œë“¤ì˜ topicì„ 'unknown'ìœ¼ë¡œ ë³€ê²½
print("âœ… [ê°œì„ ] í›ˆë ¨ ë°ì´í„°ì˜ 10%ì— Topic Dropoutì„ ì ìš©í•©ë‹ˆë‹¤...")
dropout_indices = train_df.sample(frac=0.1, random_state=42).index
# 'summarize: topic: ...' í˜•ì‹ì—ì„œ topic ë¶€ë¶„ë§Œ 'unknown'ìœ¼ë¡œ êµì²´
train_df.loc[dropout_indices, 'input_text'] = train_df.loc[dropout_indices, 'input_text'].str.replace(r'topic: .*? dialogue:', 'topic: unknown dialogue:', regex=True)

# 8. íŒŒì¼ë¡œ ì €ì¥
os.makedirs(output_dir, exist_ok=True)
train_df.to_csv(train_file, index=False)
val_df.to_csv(val_file, index=False)

print(f"ğŸ‰ ì„±ê³µ! '{train_file}'ê³¼ '{val_file}'ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.")

# prepare_data.py (ìˆ˜ì •ë³¸)
#  í›ˆë ¨ìš©ìœ¼ë¡œ 20%ì˜ ë°ì´í„°ë§Œ ì˜ë¼ì„œ train_subset.csvë¼ëŠ” íŒŒì¼ì„ ë§Œë“¤ë„ë¡ ë³€ê²½
# prepare_data.py (ìµœì¢… ìˆ˜ì •ë³¸)
# import pandas as pd
# from sklearn.model_selection import train_test_split
# import os

# print("ğŸš€ ë°ì´í„° ì¤€ë¹„ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...")

# # 1. íŒŒì¼ ê²½ë¡œ ì„¤ì •
# source_file = 'data/processed/translation_checkpoint.csv'
# output_dir = 'data/processed'
# train_file = os.path.join(output_dir, 'train.csv')
# val_file = os.path.join(output_dir, 'val.csv')
# train_subset_file = os.path.join(output_dir, 'train_subset.csv') 

# try:
#     # 2. ì›ë³¸ ë°ì´í„° ë¡œë“œ
#     df = pd.read_csv(source_file)
#     print(f"âœ… ì›ë³¸ ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(df)}ê°œ í–‰")

#     # 3. ë¹ˆ ê°’ì´ ìˆëŠ” í–‰ ì œê±°
#     original_rows = len(df)
#     df.dropna(subset=['english_dialogue', 'english_summary', 'english_topic'], inplace=True)
#     if len(df) < original_rows:
#         print(f"âœ… ë¹„ì–´ìˆëŠ” í–‰ {original_rows - len(df)}ê°œë¥¼ ì œê±°í–ˆìŠµë‹ˆë‹¤.")

#     # --- â–¼â–¼â–¼â–¼ ì´ ë¶€ë¶„ì´ ì½”ë“œì—ì„œ ë¹ ì ¸ìˆì—ˆì–´! â–¼â–¼â–¼â–¼ ---
    
#     # 4. í•„ìš”í•œ ì˜ì–´ ì»¬ëŸ¼ë§Œ ì„ íƒ
#     columns_to_use = ['english_dialogue', 'english_summary', 'english_topic']
#     df_english = df[columns_to_use].copy()

#     # 5. Flan-T5 ëª¨ë¸ì— ìµœì í™”ëœ ì…ë ¥ í˜•ì‹(input_text) ìƒì„±
#     def create_input_text(row):
#         return f"summarize: topic: {row['english_topic']} dialogue: {row['english_dialogue']}"

#     df_english['input_text'] = df_english.apply(create_input_text, axis=1)

#     # 6. ìµœì¢…ì ìœ¼ë¡œ ì‚¬ìš©í•  ì»¬ëŸ¼ë§Œ ë‚¨ê²¨ì„œ df_final ìƒì„±
#     df_final = df_english[['input_text', 'english_summary']]
#     print("âœ… 'input_text' ì»¬ëŸ¼ ìƒì„± ì™„ë£Œ.")
    
#     # --- â–²â–²â–²â–² ì—¬ê¸°ê¹Œì§€ê°€ ë¹ ì ¸ìˆë˜ ë¶€ë¶„ â–²â–²â–²â–² ---

#     # 7. í›ˆë ¨ ë°ì´í„°ì™€ ê²€ì¦ ë°ì´í„°ë¡œ ë¶„í• 
#     train_df, val_df = train_test_split(df_final, test_size=0.05, random_state=42)
#     print(f"âœ… ë°ì´í„°ë¥¼ í›ˆë ¨ ì„¸íŠ¸({len(train_df)}ê°œ)ì™€ ê²€ì¦ ì„¸íŠ¸({len(val_df)}ê°œ)ë¡œ ë¶„í•  ì™„ë£Œ.")

#     # 8. Sweepì„ ìœ„í•œ í›ˆë ¨ ë°ì´í„° ì„œë¸Œì…‹(20%) ìƒì„±
#     train_subset_df = train_df.sample(frac=0.2, random_state=42)
#     print(f"âœ… Sweep ì‹¤í—˜ìš© ì„œë¸Œì…‹ ìƒì„± ì™„ë£Œ: {len(train_subset_df)}ê°œ í–‰")

#     # 9. ëª¨ë“  íŒŒì¼ì„ ì €ì¥
#     os.makedirs(output_dir, exist_ok=True)
#     train_df.to_csv(train_file, index=False)
#     val_df.to_csv(val_file, index=False)
#     train_subset_df.to_csv(train_subset_file, index=False)

#     print(f"ğŸ‰ ì„±ê³µ! ëª¨ë“  íŒŒì¼ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.")

# except FileNotFoundError:
#     print(f"ğŸ”¥ğŸ”¥ğŸ”¥ ì—ëŸ¬: '{source_file}' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê²½ë¡œë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
# except Exception as e:
#     print(f"ğŸ”¥ğŸ”¥ğŸ”¥ ì—ëŸ¬ ë°œìƒ: {e}")