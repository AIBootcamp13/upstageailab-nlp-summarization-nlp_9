# # configs/model/flan-t5-large.yaml

name: "flan-t5-large"

pretrained_model_name_or_path: "google/flan-t5-large"

encoder_max_len: 256
decoder_max_len: 128

special_tokens:
  - '#Person1#'
  - '#Person2#'
  - '#Person3#'
  - '#Person4#'
  - '#Person5#'
  - '#Person6#'
  - '#Person7#'
  
generate_max_length: 128
num_beams: 4
no_repeat_ngram_size: 2

# learning_rate: 8e-5
learning_rate: 3e-5 # <-- 학습률을 3e-5로 수정
weight_decay: 0.01
warmup_ratio: 0.1
label_smoothing: 0.1
lr_scheduler: "cosine_with_restarts"

# 나중 시도해보기
# configs/model/flan-t5-large.yaml

# name: "flan-t5-large"

# pretrained_model_name_or_path: "google/flan-t5-large"

# encoder_max_len: 512
# decoder_max_len: 160

# special_tokens:
#   - '#Person1#'
#   - '#Person2#'
#   - '#Person3#'
#   - '#Person4#'
#   - '#Person5#'
#   - '#Person6#'
#   - '#Person7#'
  
# generate_max_length: 160
# num_beams: 5
# no_repeat_ngram_size: 2

# # learning_rate: 8e-5
# learning_rate: 1e-5        # 기존 3e-5 → 1e-5
# weight_decay: 0.01
# warmup_ratio: 0.1
# label_smoothing: 0.1
# lr_scheduler: "cosine_with_restarts"