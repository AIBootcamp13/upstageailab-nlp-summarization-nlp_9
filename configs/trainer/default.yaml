# configs/trainer/default.yaml
_target_: pytorch_lightning.Trainer

accelerator: "auto"
devices: 1
max_epochs: 20
log_every_n_steps: 50
# precision: "bf16-mixed"    
precision: "16-mixed"
gradient_clip_val: 1.0
accumulate_grad_batches: 2  # ✅ batch size 늘린 효과 (GPU 메모리 아끼면서 효과는 배로)

callbacks:
  - _target_: pytorch_lightning.callbacks.ModelCheckpoint
    dirpath: "all_checkpoints/${model.name}"
    filename: "model-{epoch}-{rougeL:.4f}" # "epoch={epoch}-rougeL={rougeL:.4f}" -> "model-{epoch}-{rougeL:.4f}"
    monitor: "rougeL"
    mode: "max"
    save_top_k: 1
    save_last: true

  - _target_: pytorch_lightning.callbacks.EarlyStopping
    monitor: "rougeL"
    mode: "max"
    patience: 5