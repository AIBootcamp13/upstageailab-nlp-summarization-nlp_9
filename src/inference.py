# src/inference.py (Hydra ì—†ëŠ” ìµœì¢… ë²„ì „)

import os
import sys
import re
import glob
import argparse
# from datetime import datetime
from datetime import datetime, timezone, timedelta # <-- ì´ ë¶€ë¶„ì„ ìˆ˜ì •/ì¶”ê°€
import pandas as pd
import torch
from omegaconf import OmegaConf
import pytorch_lightning as pl

# ìƒëŒ€ ê²½ë¡œ importë¥¼ ìœ„í•´ í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ sys.pathì— ì¶”ê°€
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from src.data_module import SummaryDataModule
from src.model_module import SummaryModelModule

def inference(cfg):
    torch.set_float32_matmul_precision('high')
    pl.seed_everything(cfg.seed)
    
    # DataModuleì€ predict stageë¥¼ ìœ„í•´ ì¸ìŠ¤í„´ìŠ¤í™”
    data_module = SummaryDataModule(cfg.data, cfg.model)
    data_module.setup(stage='predict')

    # --- ì²´í¬í¬ì¸íŠ¸ íƒìƒ‰ ë¡œì§ ---
    search_dir = os.path.join(os.getcwd(), "all_checkpoints", cfg.model.name)
    ckpt_files = glob.glob(os.path.join(search_dir, "*.ckpt"))
    
    if not ckpt_files:
        raise FileNotFoundError(f"'{cfg.model.name}' ëª¨ë¸ì˜ ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    # def get_score_from_path(p):
    #     match = re.search(r"rougeL=([\d.]+)", p)
    #     return float(match.group(1)) if match else 0
    # src/inference.py ì˜ get_score_from_path í•¨ìˆ˜ë¥¼ êµì²´

    def get_score_from_path(p):
        match = re.search(r"rougeL=([\d.]+)", p)
        if match:
            # ëì— ìžˆì„ì§€ ëª¨ë¥´ëŠ” ì (.)ì„ ì œê±°í•˜ì—¬ "0.0000." ê°™ì€ ê²½ìš°ë¥¼ ì²˜ë¦¬
            score_str = match.group(1).rstrip('.')
            return float(score_str)
        return 0

    best_ckpt_path = max(ckpt_files, key=get_score_from_path)
    print(f"'{cfg.model.name}' ëª¨ë¸ì˜ ê°€ìž¥ ì¢‹ì€ ì²´í¬í¬ì¸íŠ¸ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤: {best_ckpt_path}")

    # ì²´í¬í¬ì¸íŠ¸ë¡œë¶€í„° ëª¨ë¸ ëª¨ë“ˆ ë¡œë“œ
    model_module = SummaryModelModule.load_from_checkpoint(
        best_ckpt_path,
        model_cfg=cfg.model,
        tokenizer=data_module.tokenizer
    )

    model_module.eval()
    model_module.to(torch.device("cuda" if torch.cuda.is_available() else "cpu"))
    # ì»¤ë§¨ë“œ ë¼ì¸ generation ì„¤ì •ì„ ëª¨ë¸ì— ì£¼ìž…
    if 'generation' in cfg:
        model_module.hparams.generation = cfg.generation
        print(f"ì¶”ë¡  ì˜µì…˜ì„ ì ìš©í•©ë‹ˆë‹¤: {OmegaConf.to_container(cfg.generation)}")
    
    trainer = pl.Trainer(accelerator="auto", devices=1)
    
    print("ðŸš€ ì¶”ë¡ ì„ ì‹œìž‘í•©ë‹ˆë‹¤...")
    predictions = trainer.predict(model=model_module, dataloaders=data_module.predict_dataloader())
    print("âœ… ì¶”ë¡ ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")

    # ê²°ê³¼ ì·¨í•© ë° ì œì¶œ íŒŒì¼ ìƒì„±
    all_summaries = [summary for batch in predictions for summary in batch]
    test_df_path = os.path.join(os.getcwd(), 'data', 'raw', 'test.csv')
    test_df = pd.read_csv(test_df_path)
    submission = pd.DataFrame({'fname': test_df['fname'], 'summary': all_summaries})
    
    submissions_dir = "submissions"
    os.makedirs(submissions_dir, exist_ok=True)
    # timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

    # â–¼â–¼â–¼â–¼â–¼ íƒ€ìž„ìŠ¤íƒ¬í”„ ìƒì„± ë¶€ë¶„ì„ ì•„ëž˜ ì½”ë“œë¡œ êµì²´ â–¼â–¼â–¼â–¼â–¼
    # KST ì‹œê°„ëŒ€ (UTC+9) ì •ì˜
    kst = timezone(timedelta(hours=9))
    # í˜„ìž¬ ì‹œê°„ì„ KST ê¸°ì¤€ìœ¼ë¡œ ìƒì„±
    timestamp = datetime.now(kst).strftime("%Y%m%d_%H%M%S")
    # â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²
        
    submission_path = os.path.join(submissions_dir, f'submission_{timestamp}.csv')
    
    # ëŒ€íšŒ ê·œì •ì— ë§žê²Œ index=Falseë¡œ ì €ìž¥
    submission.to_csv(submission_path, index=True, encoding='utf-8-sig')
    print(f"ì œì¶œ íŒŒì¼ì´ '{submission_path}'ì— ì„±ê³µì ìœ¼ë¡œ ì €ìž¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("--model_name", type=str, required=True, help="e.g., flan-t5-large")
    # `num_beams`ì™€ ê°™ì€ ì¶”ë¡  ì˜µì…˜ì„ ë°›ê¸° ìœ„í•œ ì„¤ì •
    parser.add_argument("--num_beams", type=int, default=None)
    parser.add_argument("--length_penalty", type=float, default=None)
    args = parser.parse_args()

    # ì„¤ì • íŒŒì¼ ìˆ˜ë™ ë¡œë“œ ë° ë³‘í•©
    cfg = OmegaConf.load('configs/config.yaml')
    model_cfg = OmegaConf.load(f'configs/model/{args.model_name}.yaml')
    trainer_cfg = OmegaConf.load(f"configs/trainer/default.yaml")
    data_cfg = OmegaConf.load(f"configs/data/default.yaml")
    cfg.merge_with({'model': model_cfg, 'trainer': trainer_cfg, 'data': data_cfg})
    
    # ì»¤ë§¨ë“œ ë¼ì¸ ì¸ìžë¥¼ generation ì„¤ì •ìœ¼ë¡œ ì¶”ê°€
    generation_cfg = {
        'num_beams': args.num_beams,
        'length_penalty': args.length_penalty
    }
    cfg.merge_with({'generation': generation_cfg})
    
    inference(cfg)