# src/validate.py
# ìµœê³ ì˜ num_beams ê°’ ì°¾ê¸°
import os
import sys
import re
import glob
import argparse
import pandas as pd
import torch
from omegaconf import OmegaConf
import pytorch_lightning as pl
import evaluate  # evaluate ë¼ì´ë¸ŒëŸ¬ë¦¬ ì¶”ê°€

# ìƒëŒ€ ê²½ë¡œ importë¥¼ ìœ„í•´ í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ sys.pathì— ì¶”ê°€
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from src.data_module import SummaryDataModule
from src.model_module import SummaryModelModule

os.environ["TOKENIZERS_PARALLELISM"] = "false"

def validate(cfg):
    torch.set_float32_matmul_precision('high')
    pl.seed_everything(cfg.seed)
    
    # DataModuleì„ 'fit' ìŠ¤í…Œì´ì§€ë¡œ ì„¤ì •í•˜ì—¬ val_dataloaderë¥¼ ì¤€ë¹„
    data_module = SummaryDataModule(cfg.data, cfg.model)
    data_module.setup(stage='fit')

    # --- ì²´í¬í¬ì¸íŠ¸ íƒìƒ‰ ë¡œì§ ---
    search_dir = os.path.join(os.getcwd(), "all_checkpoints", cfg.model.name)
    ckpt_files = glob.glob(os.path.join(search_dir, "*.ckpt"))
    
    if not ckpt_files:
        raise FileNotFoundError(f"'{cfg.model.name}' ëª¨ë¸ì˜ ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    def get_score_from_path(p):
        # ROUGE-L ì ìˆ˜ë¥¼ ì°¾ë„ë¡ ì •ê·œí‘œí˜„ì‹ ìˆ˜ì •
        match = re.search(r"rougeL=([\d.]+)", p)
        if match:
            # ëì— ìˆì„ì§€ ëª¨ë¥´ëŠ” ì (.)ì„ ì œê±°í•˜ì—¬ "0.0000." ê°™ì€ ê²½ìš°ë¥¼ ì²˜ë¦¬
            score_str = match.group(1).rstrip('.')
            return float(score_str)
        return 0

    best_ckpt_path = max(ckpt_files, key=get_score_from_path)
    print(f"'{cfg.model.name}' ëª¨ë¸ì˜ ê°€ì¥ ì¢‹ì€ ì²´í¬í¬ì¸íŠ¸ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤: {best_ckpt_path}")

    model_module = SummaryModelModule.load_from_checkpoint(
        best_ckpt_path,
        model_cfg=cfg.model,
        tokenizer=data_module.tokenizer
    )

    model_module.eval()
    model_module.to(torch.device("cuda" if torch.cuda.is_available() else "cpu"))
    if 'generation' in cfg:
        model_module.hparams.generation = cfg.generation
        print(f"ì¶”ë¡  ì˜µì…˜ì„ ì ìš©í•©ë‹ˆë‹¤: {OmegaConf.to_container(cfg.generation)}")
    
    trainer = pl.Trainer(accelerator="auto", devices=1)
    
    print("ğŸš€ ê²€ì¦ ë°ì´í„°ë¡œ ì¶”ë¡ ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
    # datamodule ëŒ€ì‹  val_dataloaderë¥¼ ì§ì ‘ ì „ë‹¬
    predictions = trainer.predict(model=model_module, dataloaders=data_module.val_dataloader())
    print("âœ… ì¶”ë¡ ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")

    # --- ROUGE ì ìˆ˜ ê³„ì‚° ë¡œì§ ì¶”ê°€ ---
    print("ğŸ’¯ ROUGE ì ìˆ˜ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤...")
    all_summaries = [summary for batch in predictions for summary in batch]
    
    # val.csv íŒŒì¼ì—ì„œ ì •ë‹µ ìš”ì•½ë¬¸(references) ë¶ˆëŸ¬ì˜¤ê¸°
    val_df = pd.read_csv(cfg.data.val_path)
    references = val_df['english_summary'].tolist()

    # ROUGE ê³„ì‚°ê¸° ë¡œë“œ ë° ì ìˆ˜ ê³„ì‚°
    rouge_metric = evaluate.load("rouge")
    rouge_metric.add_batch(predictions=all_summaries, references=references)
    results = rouge_metric.compute()

    print("\n--- ê²€ì¦ ê²°ê³¼ (ROUGE Scores) ---")
    print(results)
    print("---------------------------------")


if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("--model_name", type=str, required=True, help="e.g., flan-t5-large")
    parser.add_argument("--num_beams", type=int, default=None)
    parser.add_argument("--length_penalty", type=float, default=None)
    args = parser.parse_args()

    cfg = OmegaConf.load('configs/config.yaml')
    model_cfg = OmegaConf.load(f'configs/model/{args.model_name}.yaml')
    trainer_cfg = OmegaConf.load(f"configs/trainer/default.yaml")
    data_cfg = OmegaConf.load(f"configs/data/default.yaml")
    cfg.merge_with({'model': model_cfg, 'trainer': trainer_cfg, 'data': data_cfg})
    
    generation_cfg = {
        'num_beams': args.num_beams,
        'length_penalty': args.length_penalty
    }
    cfg.merge_with({'generation': generation_cfg})
    
    validate(cfg)